## ----echo = FALSE, warning = FALSE, message=FALSE----------------
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  comment = "",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE,
  fig.retina = 4
)


## ----echo=FALSE--------------------------------------------------
library(tidyverse)
library(ggthemes)
library(maps)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(nullabor)
library(splitstackshape)
library(plotly)
library(forecast)
library(readxl)
# remotes::install_github("wmurphyrd/fiftystater")
library(fiftystater)
# remotes::install_github("heike/vinference")
library(vinference)


## ----lineup 1, fig.height=8, fig.width=8-------------------------
# Make a lineup of the mtcars data, 20 plots, one is the data, 
# and the others are null plots. Which one is different?
set.seed(20190709)
ggplot(lineup(null_permute('mpg'), mtcars), aes(mpg, wt)) +
  geom_point() +
  facet_wrap(~ .sample)


## ----embed the data plot in a field of null plots, eval=FALSE----
## library(nullabor)
## pos <- sample(1:20, 1)
## df_null <- lineup(null_permute('v1'), df, pos=pos)
## ggplot(df_null, aes(x=v2, y=v1, fill=v2)) +
##   geom_boxplot() +
##   facet_wrap(~.sample, ncol=5) + coord_flip()


## ----compute pvalue----------------------------------------------
pvisual(4, 17, m=20)


## ----adjusted for variability in the plots-----------------------
res <- c(vinference::pVis(4,17,m=20, alpha=0.01, lower.tail=FALSE),
         vinference::pVis(4,17,m=20, alpha=0.15, lower.tail=FALSE),
         vinference::pVis(4,17,m=20, alpha=1, lower.tail=FALSE))
names(res) <- c("alpha = 0.01", "alpha = 0.15", "alpha = 1")
res


## ----lineup 2, fig.height=6--------------------------------------
# Assessing model fit, using a lineup of residual plots, 19 are nulls, and one is the 
# residual plot. Is there structure in the residual plot that identifies it as having 
# less than random variation. Nulls are generated by `rotating` residuals after model fit.
tips <- read_csv("http://www.ggobi.org/book/data/tips.csv")
x <- lm(tip ~ totbill, data = tips)
tips.reg <- data.frame(tips, .resid = residuals(x), .fitted = fitted(x))
ggplot(lineup(null_lm(tip ~ totbill, method = 'rotate'), tips.reg)) +
  geom_point(aes(x = totbill, y = .resid)) +
  facet_wrap(~ .sample)


## ----lineup 3, fig.height=6--------------------------------------
# Assessing time series model fit using simulation to produce null plots.
data(aud)
l <- lineup(null_ts("rate", auto.arima), aud)
ggplot(l, aes(x=date, y=rate)) + geom_line() +
  facet_wrap(~.sample, scales="free_y") +
  theme(axis.text = element_blank()) +
  xlab("") + ylab("")


## ----lets talk TB, echo=FALSE------------------------------------
tb <- read_csv(here::here("data/TB_notifications_2019-07-01.csv")) %>% 
  dplyr::select(country, iso3, year, new_sp_m04:new_sp_fu) %>%
  pivot_longer(cols=new_sp_m04:new_sp_fu, names_to="sexage", values_to="count") %>%
  mutate(sexage = str_replace(sexage, "new_sp_", "")) %>%
  mutate(sex=substr(sexage, 1, 1), 
         age=substr(sexage, 2, length(sexage))) %>%
  dplyr::select(-sexage)

# Filter years between 1997 and 2012 due to missings
tb_us <- tb %>% 
  filter(country == "United States of America") %>%
  filter(!(age %in% c("04", "014", "514", "u"))) %>%
  filter(year > 1996, year < 2013)


## ----fig.width=10, fig.height=3----------------------------------
ggplot(tb_us, aes(x = year, y = count, fill = sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(~ age) +
  scale_fill_brewer(palette="Dark2")


## ----generate a lineup of three binomial simulations, echo=TRUE----
# Make expanded rows of categorical variables
# matching the counts of aggregated data.
# sex needs to be converted to 0, 1 to 
# match binomial simulations
tb_us_long <- expandRows(tb_us, "count")
tb_us_long <- tb_us_long %>%
  mutate(sex01 = ifelse(sex=="m", 0, 1)) %>%
  select(-sex)

# Generate a lineup of three, randomly choose one of the
# positions to place true data.
# Compute counts again.
pos = sample(1:3, 1)
l <- lineup(null_dist(var="sex01", dist="binom", 
                      list(size=1, p=0.5)), 
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(sex01)


## ----plot the lineup, fig.height=8, fig.width=10-----------------
ggplot(l, aes(x = year, y = n, fill = factor(sex01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") + 
  theme(legend.position="none")


## ----a more complicated null, echo=TRUE--------------------------
# Compute proportion across all data
tbl <- tb_us %>% group_by(sex) %>% summarise(count=sum(count))
tbl
p <- tbl$count[1]/sum(tbl$count)

pos = sample(1:3, 1)
l <- lineup(null_dist(var="sex01", dist="binom", 
                      list(size=1, p=p)), 
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(sex01)



## ----fig.height=8, fig.width=10----------------------------------
ggplot(l, aes(x = year, y = n, fill = factor(sex01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") + 
  theme(legend.position="none")


## ----make a map lineup, fig.height=6, fig.width=10---------------
# Read xlsx spreadsheet on cancer incidence in USA, for a more
# complex lneup example, a lineup of maps
incd <- read_xlsx(here::here("data/IncRate.xlsx"), skip=6, sheet=2) %>%
  filter(!(State %in% c("All U.S. combined", "Kansas"))) %>%
  select(State, `Melanoma of the skin / Both sexes combined`) %>%
  rename(Incidence=`Melanoma of the skin / Both sexes combined`) %>%
  mutate(Incidence = as.numeric(substr(Incidence, 1, 3)))

# State names need to coincide between data sets
incd <- incd %>% mutate(State = tolower(State))

# Choose a position 
pos <- 6

# Make lineup of cancer incidence
incd_lineup <- lineup(null_permute('Incidence'), incd, n=12, pos=pos)

# Join cancer incidence data to map polygons
incd_map <- left_join(fifty_states, filter(incd_lineup, .sample==1),
                      by=c("id"="State"))
for (i in 2:12) {
  x <- left_join(fifty_states, filter(incd_lineup, .sample==i),
                      by=c("id"="State"))
  incd_map <- bind_rows(incd_map, x)
}
# Remove Kansas - it was missing the cancer data
incd_map <- incd_map %>% filter(!is.na(.sample))

# Plot the maps as a lineup
#library(mapproj)
ggplot(incd_map) + 
  geom_polygon(aes(x=long, y=lat, fill = Incidence, group=group)) + 
  expand_limits(x = incd_map$long, y = incd_map$lat) +
  #coord_map() +
  scale_x_continuous(breaks = NULL) + 
  scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "") +
  scale_fill_distiller(palette="YlGn", type="seq", direction=1) +
  theme(legend.position = "none", 
        panel.background = element_blank()) +
  facet_wrap(~.sample, ncol=4)


## ----eval=FALSE,echo=TRUE----------------------------------------
## library(MASS)
## data(wasps)
## lda_pred <- function(x) {
##   d <- predict(lda(Group~.,
##                    data=x[,-43]))$x[,1:2] %>%
##   as_tibble() %>%
##   mutate(Group = x$Group)
##   return(d)
## }
## wasps_lineup <- lineup(null_permute('Group'),
##                        wasps[,-1], n=12) %>%
##   as_tibble()
## wasps_lineup_lda <- wasps_lineup %>%
##   split(.$.sample) %>%
##   map_df(~lda_pred(.)) %>%
##   mutate(.sample = wasps_lineup$.sample)
## ggplot(wasps_lineup_lda, aes(x=LD1, y=LD2,
##                              colour=Group)) +
##   geom_point() +
##   facet_wrap(~.sample, ncol=4) +
##   scale_colour_brewer(palette="Dark2") +
##   theme(legend.position="none")

